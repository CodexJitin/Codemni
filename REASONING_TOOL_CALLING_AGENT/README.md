# ü§ñ Reasoning Tool Calling Agent

A fast and efficient AI agent with basic reasoning capabilities and tool execution. Perfect for production environments where speed and cost-efficiency are priorities.

## üìã Overview

The `Create_ToolCalling_Agent` provides a balanced approach to AI tool calling with:

- **Fast Execution**: ~2.4x faster than the deep reasoning agent
- **Cost-Efficient**: 50-70% lower token usage
- **Thinking Display**: Shows basic reasoning for transparency
- **Simple Structure**: Easy to understand and maintain
- **Production-Ready**: Reliable for high-volume applications

**‚ö° Performance Note:** This agent averages 4.63s per query compared to 11.11s for the deep reasoning agent, making it ideal for production APIs and real-time applications.

## ‚ú® Key Features

### 1. **Basic Thinking Display**
- Shows thought process before action
- Simple, clear reasoning
- Sufficient for most tasks
- Low overhead

### 2. **Tool Call Decision**
- Identifies which tool to use
- Determines appropriate parameters
- Executes tool calls efficiently

### 3. **Memory Integration**
- Optional conversation history
- Maintains context across interactions
- Works with all memory types

### 4. **Custom Prompts**
- Flexible agent personality
- Role-specific behavior
- Easy customization

### 5. **Verbose Mode Control**
- Silent mode for production
- Debug mode for development
- Fine-grained logging control

## üÜö Comparison: Reasoning vs Deep Reasoning Agent

| Feature | REASONING Agent ‚úÖ | DEEP_REASONING Agent |
|---------|-------------------|----------------------|
| **Speed** | ‚ö° Fast (4.63s avg) | üê¢ Slower (11.11s avg) |
| **Token Usage** | üí∞ Low (600-900) | üí∏ High (1500-2800) |
| **Thinking Display** | ‚úÖ Basic | ‚úÖ Deep chain-of-thought |
| **Problem Analysis** | ‚ö†Ô∏è Minimal | ‚úÖ Comprehensive breakdown |
| **Situation Awareness** | ‚ùå None | ‚úÖ Dynamic context tracking |
| **Reasoning Depth** | ‚ö†Ô∏è Surface-level | ‚úÖ Multi-layered reasoning |
| **Self-Reflection** | ‚ùå None | ‚úÖ Confidence + alternatives |
| **Error Recovery** | ‚ö†Ô∏è Basic retry | ‚úÖ Strategic alternatives |
| **Best For** | Production APIs ‚úÖ | Research & Debugging |
| **Cost** | üí∞ Low | üí∏ High |
| **Complexity** | üü¢ Simple | üü° Complex |

## üìñ Usage

### Basic Setup

```python
from REASONING_TOOL_CALLING_AGENT.agent import Create_ToolCalling_Agent
from llm.Google_llm import GoogleLLM

# Initialize LLM
llm = GoogleLLM(
    model="gemini-2.0-flash-thinking-exp-1219",
    api_key="your-api-key"
)

# Create reasoning agent
agent = Create_ToolCalling_Agent(
    llm=llm,
    verbose=True  # Enable verbose output
)

# Add tools
def calculator(expression):
    """Evaluate mathematical expressions"""
    return str(eval(expression))

agent.add_tool(
    "calculator",
    "Evaluate mathematical expressions",
    calculator
)

# Use the agent
response = agent.invoke("What is 144 divided by 12?")
print(response)
```

### With Memory

```python
from memory import ConversationalWindowMemory

# Create memory instance
memory = ConversationalWindowMemory(window_size=10)

# Create agent with memory
agent = Create_ToolCalling_Agent(
    llm=llm,
    memory=memory,
    verbose=True
)

# Now the agent remembers conversation history
agent.invoke("Calculate 50 + 30")
agent.invoke("Multiply the previous result by 2")  # Remembers context
```

### With Custom Prompt

```python
# Define agent personality/role
custom_intro = "You are a friendly math tutor who loves helping students."

agent = Create_ToolCalling_Agent(
    llm=llm,
    prompt=custom_intro,  # Custom agent personality
    verbose=True
)

# Agent behavior reflects the custom prompt
```

### Silent Mode (Production)

```python
# For production - no logging
agent = Create_ToolCalling_Agent(
    llm=llm,
    verbose=False  # Silent mode
)

response = agent.invoke("Calculate something")
# Only returns final response, no intermediate logs
```

## üîß Configuration Options

```python
Create_ToolCalling_Agent(
    llm,                       # Required: LLM instance
    verbose=False,             # Show detailed logs (default: False)
    prompt=None,               # Custom agent introduction (optional)
    memory=None                # Memory instance for history (optional)
)
```

### Parameters

- **`llm`** (required): LLM instance with `generate_response()` method
  - Supported: Google, OpenAI, Anthropic, Groq, Ollama
  
- **`verbose`** (bool): Control output verbosity
  - `True`: Show thinking, tool calls, and results
  - `False`: Only return final response (production mode)
  
- **`prompt`** (str, optional): Custom agent personality
  - Should ONLY contain agent role/personality description
  - Tool instructions are added automatically
  - Example: "You are a financial advisor"
  
- **`memory`** (object, optional): Memory for conversation history
  - `ConversationalBufferMemory`: Stores all history
  - `ConversationalWindowMemory`: Stores last N messages
  - `ConversationalSummaryMemory`: Stores summarized history
  - `ConversationalTokenBufferMemory`: Token-limited history

## üìä Response Structure

### With verbose=True

```
ü§î Thinking:
  Need to divide 144 by 12 using the calculator tool

üîß Tool: calculator
üìã Parameters: {'expression': '144 / 12'}
‚úÖ Result: 12.0

üì§ Final Response:
  144 divided by 12 equals 12.0
```

### With verbose=False

```
144 divided by 12 equals 12.0
```

## üéØ Best Use Cases

### ‚úÖ Ideal For

- **Production APIs**: Fast response times critical
- **High-Volume Applications**: Cost-sensitive operations
- **Real-Time Systems**: Low latency requirements
- **Mobile Apps**: Quick responses needed
- **Chatbots**: Conversational interfaces
- **Simple Queries**: Straightforward tool calls
- **Cost Optimization**: Token usage matters

### ‚ö†Ô∏è Not Ideal For

- **Complex Multi-Step Reasoning**: Use Deep Reasoning agent
- **Educational/Debugging**: Limited reasoning visibility
- **High-Stakes Decisions**: No confidence scoring
- **Research Applications**: Minimal transparency
- **Error Recovery**: Basic retry logic only

## üöÄ Advanced Features

### Adding Multiple Tools

```python
def calculator(expression):
    return str(eval(expression))

def get_time():
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def string_length(text):
    return str(len(text))

# Add all tools
agent.add_tool("calculator", "Evaluate math expressions", calculator)
agent.add_tool("get_time", "Get current date and time", get_time)
agent.add_tool("string_length", "Calculate string length", string_length)
```

### Dynamic Tool Addition

```python
# Add tools dynamically based on context
if user_needs_math:
    agent.add_tool("calculator", "Math operations", calculator)

if user_needs_time:
    agent.add_tool("get_time", "Time operations", get_time)
```

### Updating LLM or Memory

```python
# Switch LLM
new_llm = OpenAI_LLM(model="gpt-4", api_key="key")
agent.add_llm(new_llm)

# Add memory later
memory = ConversationalBufferMemory()
agent.add_memory(memory)
```

## üìù Example Queries

### Simple Calculation

```python
response = agent.invoke("What is 25 multiplied by 4, plus 50?")
# Output: "The result is 150"
```

### With Context (using memory)

```python
agent.invoke("Calculate 100 times 5")
agent.invoke("Now divide the result by 2")  # Uses memory context
# Output: "The result is 250"
```

### Multi-Tool Usage

```python
response = agent.invoke(
    "What is the length of 'Hello World' multiplied by 5?"
)
# Uses: string_length tool ‚Üí calculator tool
```

## ‚ö° Performance Metrics

Based on comprehensive testing:

| Metric | Value | Notes |
|--------|-------|-------|
| **Average Speed** | 4.63s | Per query execution |
| **Token Usage** | 600-900 | Average per query |
| **Success Rate** | 100% | All test cases passed |
| **Speed vs Deep** | 2.4x faster | Significant advantage |
| **Cost vs Deep** | 50-70% cheaper | Token savings |

## üéì When to Choose This Agent

### Choose REASONING_TOOL_CALLING_AGENT When

‚úÖ Speed is important (production APIs)  
‚úÖ Cost optimization matters (high volume)  
‚úÖ Simple to moderate complexity queries  
‚úÖ Real-time responses needed  
‚úÖ Basic reasoning transparency sufficient  
‚úÖ Straightforward tool calling  
‚úÖ Production deployment  

### Choose DEEP_REASONING_TOOL_CALLING_AGENT When

‚ùå Complex multi-step reasoning required  
‚ùå Need deep transparency into thinking  
‚ùå Educational or debugging purposes  
‚ùå High-stakes decision making  
‚ùå Research and analysis  
‚ùå Error recovery critical  
‚ùå Confidence scoring needed  

## üîç JSON Response Format

The agent expects this JSON structure from the LLM:

```json
{
    "Thinking": "Brief reasoning about the query",
    "Tool call": "tool_name",
    "Tool Parameters": {
        "param1": "value1",
        "param2": "value2"
    },
    "Final Response": "None"
}
```

When no tool is needed:

```json
{
    "Thinking": "Can answer directly without tools",
    "Tool call": "None",
    "Tool Parameters": "None",
    "Final Response": "The direct answer to the user"
}
```

## üí° Tips and Best Practices

### 1. **Use verbose=False in Production**
```python
# Development
dev_agent = Create_ToolCalling_Agent(llm=llm, verbose=True)

# Production
prod_agent = Create_ToolCalling_Agent(llm=llm, verbose=False)
```

### 2. **Keep Tool Descriptions Clear**
```python
# Good
agent.add_tool("calc", "Evaluate math expressions like '2+2' or '10*5'", calculator)

# Too vague
agent.add_tool("calc", "Do math", calculator)
```

### 3. **Use Memory for Multi-Turn Conversations**
```python
memory = ConversationalWindowMemory(window_size=10)
agent = Create_ToolCalling_Agent(llm=llm, memory=memory)
```

### 4. **Custom Prompts for Specific Domains**
```python
# For financial advisor
prompt = "You are a professional financial advisor with expertise in investments."
agent = Create_ToolCalling_Agent(llm=llm, prompt=prompt)
```

### 5. **Tool Naming Conventions**
- Use lowercase with underscores: `get_weather`, `calculate_tax`
- Be descriptive: `convert_currency` not `conv`
- Avoid special characters

## üêõ Troubleshooting

### Issue: Agent not using tools

**Solution**: Check tool descriptions are clear and match the query

```python
# Make sure description is specific
agent.add_tool(
    "calculator",
    "Evaluate mathematical expressions like addition, subtraction, multiplication, division",
    calculator
)
```

### Issue: Memory not working

**Solution**: Ensure memory is properly initialized

```python
from memory import ConversationalBufferMemory

memory = ConversationalBufferMemory()
agent = Create_ToolCalling_Agent(llm=llm, memory=memory)
```

### Issue: Custom prompt not working

**Solution**: Only include agent personality, not tool instructions

```python
# ‚úÖ Correct
prompt = "You are a friendly assistant"

# ‚ùå Wrong - don't include tool instructions
prompt = "You are an assistant. Use tools by returning JSON..."
```

## üìö Related

- **DEEP_REASONING_TOOL_CALLING_AGENT**: For complex reasoning needs
- **TOOL_CALLING_AGENT**: Basic tool calling without reasoning
- **Memory Modules**: `memory/` folder for conversation history
- **LLM Wrappers**: `llm/` folder for different LLM providers

## üèÜ Summary

**REASONING_TOOL_CALLING_AGENT** is the **recommended choice** for:

- ‚úÖ Production applications
- ‚úÖ Cost-sensitive deployments  
- ‚úÖ High-volume requests
- ‚úÖ Real-time systems
- ‚úÖ Simple to moderate complexity
- ‚úÖ When basic reasoning is sufficient

**Performance**: Fast, reliable, and cost-efficient while maintaining reasoning transparency.

---

**Note**: For queries requiring deep reasoning, problem analysis, confidence scoring, and error recovery strategies, consider using `DEEP_REASONING_TOOL_CALLING_AGENT` instead.
