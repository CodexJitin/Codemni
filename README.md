# Codemni

<div align="center">

<img src="./assets/codemni-logo.png" alt="Codemni Logo" width="400"/>

**ğŸš€ Production-Ready Python Toolkit for AI Development**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub](https://img.shields.io/badge/GitHub-CodexJitin%2FCodemni-181717?logo=github)](https://github.com/CodexJitin/Codemni)

*A modular collection of production-ready tools and utilities for modern AI-powered Python applications*

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Modules](#-modules) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation)

</div>

---

## ğŸ“– About

**Codemni** is a comprehensive Python toolkit designed to accelerate AI development with robust, production-ready components. Built with a focus on:

- âœ¨ **Production-Ready**: Battle-tested with built-in error handling, retries, and timeouts
- ğŸ¯ **Modular Design**: Use only what you need, keep dependencies minimal
- ğŸ”§ **Developer-Friendly**: Consistent APIs, clear documentation, and intuitive interfaces
- ğŸš€ **Performance**: Optimized for speed and reliability
- ğŸ›¡ï¸ **Robust**: Comprehensive exception handling and defensive coding

---

## ğŸ§© Modules

### ğŸ“¡ [LLM Module](./llm/) - Large Language Model Wrappers

Production-ready wrappers for popular LLM providers with unified interface.

**Supported Providers:**
- ğŸ”· Google Gemini (`gemini-pro`, `gemini-1.5-pro`)
- ğŸŸ¢ OpenAI (`gpt-4`, `gpt-3.5-turbo`, `gpt-4-turbo`)
- ğŸŸ£ Anthropic Claude (`claude-3-opus`, `claude-3-sonnet`, `claude-3-haiku`)
- âš¡ Groq (`llama3-70b`, `mixtral-8x7b`)
- ğŸ¦™ Ollama (Local models: `llama2`, `mistral`, `codellama`)

**Key Features:**
- Automatic retries with exponential backoff
- Configurable timeouts
- Consistent API across all providers
- Silent operation (no logging)
- Minimal dependencies

**[ğŸ“š Full LLM Documentation â†’](./llm/README.md)**

---

## ğŸ“¦ Installation

### Quick Install

```bash
# Clone the repository
git clone https://github.com/CodexJitin/Codemni.git
cd Codemni

# Install the package
pip install -e .
```

### Direct from GitHub

```bash
pip install git+https://github.com/CodexJitin/Codemni.git
```

### Install with Optional Dependencies

```bash
# Install with specific LLM providers
pip install -e .[openai]        # OpenAI support
pip install -e .[anthropic]     # Anthropic Claude support
pip install -e .[groq]          # Groq support
pip install -e .[google]        # Google Gemini support
pip install -e .[ollama]        # Ollama (local) support

# Install with all LLM providers
pip install -e .[all]
```

---

## ğŸš€ Quick Start

### LLM Module - Basic Usage

```python
from Codemni.llm import google_llm, openai_llm, anthropic_llm

# Google Gemini
response = google_llm(
    prompt="Explain quantum computing in simple terms",
    model="gemini-pro",
    api_key="your-api-key"  # or set GOOGLE_API_KEY env var
)
print(response)

# OpenAI GPT
response = openai_llm(
    prompt="Write a Python function to calculate fibonacci",
    model="gpt-4",
    temperature=0.7,
    max_tokens=500
)
print(response)

# Anthropic Claude
response = anthropic_llm(
    prompt="Explain the concept of recursion",
    model="claude-3-sonnet-20240229",
    max_tokens=300
)
print(response)
```

### Error Handling

```python
from Codemni.llm import google_llm, GoogleLLMError, GoogleLLMAPIError

try:
    response = google_llm(
        prompt="Hello, world!",
        model="gemini-pro"
    )
    print(response)
except GoogleLLMAPIError as e:
    print(f"API Error: {e}")
except GoogleLLMError as e:
    print(f"General Error: {e}")
```

---

## ğŸ” Configuration

### Environment Variables

Set these to avoid hardcoding API keys:

```bash
# Linux/Mac
export GOOGLE_API_KEY="your-google-key"
export OPENAI_API_KEY="your-openai-key"
export ANTHROPIC_API_KEY="your-anthropic-key"
export GROQ_API_KEY="your-groq-key"
export OLLAMA_BASE_URL="http://localhost:11434"  # Optional

# Windows PowerShell
$env:GOOGLE_API_KEY="your-google-key"
$env:OPENAI_API_KEY="your-openai-key"
```

### Using .env File

```bash
# Install python-dotenv
pip install python-dotenv
```

```python
from dotenv import load_dotenv
load_dotenv()

# Now your environment variables are loaded
from Codemni.llm import google_llm

response = google_llm(prompt="Hello", model="gemini-pro")
```

---

## ğŸ—ï¸ Project Structure

```
Codemni/
â”œâ”€â”€ ğŸ“„ README.md              # This file - Main documentation
â”œâ”€â”€ ğŸ“„ LICENSE                # License information
â”œâ”€â”€ ğŸ“„ setup.py               # Package configuration
â”œâ”€â”€ ğŸ“„ requirements.txt       # Base dependencies
â”œâ”€â”€ ğŸ“„ __init__.py            # Package initialization
â”œâ”€â”€ ğŸ“„ example_usage.py       # Quick examples
â”‚
â”œâ”€â”€ ğŸ“ llm/                   # LLM Module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md             # LLM module documentation
â”‚   â”œâ”€â”€ Google_llm.py         # Google Gemini wrapper
â”‚   â”œâ”€â”€ OpenAI_llm.py         # OpenAI wrapper
â”‚   â”œâ”€â”€ Anthropic_llm.py      # Anthropic wrapper
â”‚   â”œâ”€â”€ Groq_llm.py           # Groq wrapper
â”‚   â”œâ”€â”€ Ollama_llm.py         # Ollama wrapper
â”‚   â””â”€â”€ examples.py           # Usage examples
â”‚
â””â”€â”€ ğŸ“ [Future Modules]       # Coming soon...
    â””â”€â”€ ...
```

---

## ğŸ“š Documentation

### Module Documentation

- **[LLM Module](./llm/README.md)** - Comprehensive guide to LLM wrappers
  - API reference for all providers
  - Advanced usage examples
  - Exception handling guide
  - Provider-specific notes

### Examples

- `example_usage.py` - Quick start examples for all modules
- `llm/examples.py` - Detailed LLM provider examples

---

## âœ¨ Features by Module

### LLM Module

| Feature | Description |
|---------|-------------|
| ğŸ”„ **Auto Retry** | Exponential backoff for transient failures |
| â±ï¸ **Timeouts** | Configurable request timeouts (30-60s) |
| ğŸ›¡ï¸ **Error Handling** | Clear exception hierarchy per provider |
| ğŸ”‡ **Silent Mode** | No logging - clean operation |
| ğŸ“¦ **Minimal Deps** | Install only what you need |
| ğŸ¯ **Unified API** | Same interface across all providers |
| âœ… **Validation** | Input validation and defensive coding |

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push to the branch (`git push origin feature/AmazingFeature`)
5. ğŸ”€ Open a Pull Request

### Development Guidelines

- Follow existing code style and patterns
- Add tests for new features
- Update documentation
- Keep dependencies minimal
- Maintain backward compatibility

---

## ğŸ“‹ Requirements

- Python 3.8 or higher
- Optional dependencies (install as needed):
  - `openai>=1.0.0` - For OpenAI support
  - `anthropic>=0.18.0` - For Anthropic support
  - `groq>=0.4.0` - For Groq support
  - `google-generativeai>=0.3.0` - For Google Gemini support
  - `ollama>=0.1.0` - For Ollama support

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**CodexJitin**

- GitHub: [@CodexJitin](https://github.com/CodexJitin)
- Repository: [Codemni](https://github.com/CodexJitin/Codemni)

---

## ğŸ”– Version

**Current Version: 1.0.0**

### Changelog

#### v1.0.0 (2025-10-24)
- ğŸ‰ Initial release
- âœ… LLM module with 5 provider support
- âœ… Production-ready error handling
- âœ… Comprehensive documentation

---

## ğŸŒŸ Show Your Support

If you find Codemni useful, please consider:
- â­ Starring the repository
- ğŸ› Reporting bugs
- ğŸ’¡ Suggesting new features
- ğŸ”€ Contributing code

---

## ğŸ“ Support

- ğŸ“§ Issues: [GitHub Issues](https://github.com/CodexJitin/Codemni/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/CodexJitin/Codemni/discussions)

---

<div align="center">

**Made with â¤ï¸ by CodexJitin**

*Empowering developers to build better AI applications*

</div>
